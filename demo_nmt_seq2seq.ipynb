{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Machine Translation\n",
    "\n",
    "##  Requirements:\n",
    "* Python 2.7\n",
    "* PyTorch\n",
    "* NumPy\n",
    "* NLTK\n",
    "* Data: download [German-English](http://www.manythings.org/anki/deueng.zip) and extract as deu.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from io import open\n",
    "from unicodedata import normalize\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import nltk\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0'\n",
    "\n",
    "file_name   = './deu.txt'\n",
    "token_PAD   = 0\n",
    "token_BEGIN = 1\n",
    "token_END   = 2\n",
    "MIN_WORD_COUNT   = 10\n",
    "MIN_SENTENCE_LENGTH = 3\n",
    "MAX_SENTENCE_LENGTH = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions to read sentence pairs from deu.txt \n",
    "* deu.txt is downloaded and unzipped to current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#####################################################################################\n",
    "# clean sentence string read from deu.txt\n",
    "#####################################################################################\n",
    "def clean_string(sentence):    \n",
    "    sentence = normalize('NFD', sentence).encode('ascii', 'ignore').decode('UTF-8')\n",
    "    sentence = sentence.lower().strip() \n",
    "    sentence = re.sub(r'[^\\w\\s]', r' ', sentence)\n",
    "    return ' '.join(sentence.split())\n",
    "\n",
    "#####################################################################################\n",
    "# read sentence pairs from deu.txt and remove too long / too short sentence pairs\n",
    "#####################################################################################\n",
    "def read_string(file_name):\n",
    "    lines = open(file_name, encoding='utf-8').read().strip().split('\\n')\n",
    "    pairs = [[clean_string(s) for s in l.split('\\t')] for l in lines]\n",
    "    pairs = [list(reversed(p)) for p in pairs]\n",
    "\n",
    "    pairs_new = []\n",
    "    for pair in pairs:\n",
    "        if min([len(pair[0]), len(pair[1])]) > MIN_SENTENCE_LENGTH and \\\n",
    "           max([len(pair[0]), len(pair[1])]) < MAX_SENTENCE_LENGTH:\n",
    "                pairs_new.append(pair)\n",
    "    return np.array(pairs_new), len(pairs), len(pairs_new)\n",
    "\n",
    "#####################################################################################\n",
    "# tokenize German and English vocabulary\n",
    "#####################################################################################\n",
    "class tokenizer:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.index_dict = {token_BEGIN: \"TBEGIN\", token_END: \"TEND\", token_PAD: \"TPAD\"}\n",
    "        self.word_dict = {}\n",
    "        self.word_count = {}\n",
    "        self.word_num = 3 \n",
    "        self.trimmed = False\n",
    "\n",
    "    def read_sentences(self, sentences):\n",
    "        for sentence in sentences:\n",
    "            for word in sentence.split(' '):\n",
    "                self.read_word(word)\n",
    "\n",
    "    def read_word(self, word):\n",
    "        if word not in self.word_dict:\n",
    "            self.index_dict[self.word_num] = word\n",
    "            self.word_dict[word] = self.word_num\n",
    "            self.word_count[word] = 1            \n",
    "            self.word_num += 1\n",
    "        else:\n",
    "            self.word_count[word] += 1      \n",
    "    \n",
    "    def trim_word(self, min_count):\n",
    "        if self.trimmed: return\n",
    "        self.trimmed = True        \n",
    "        keep_words = []\n",
    "        \n",
    "        for k, v in self.word_count.items():\n",
    "            if v >= min_count:\n",
    "                keep_words.append(k)\n",
    "        \n",
    "        self.index_dict = {token_BEGIN: \"TBEGIN\", token_END: \"TEND\", token_PAD: \"TPAD\"}\n",
    "        self.word_dict = {}        \n",
    "        self.word_count = {}\n",
    "        self.word_num = 3 \n",
    "\n",
    "        for word in keep_words:\n",
    "            self.read_word(word)\n",
    "\n",
    "#####################################################################################\n",
    "# remove sentence pairs with rare words\n",
    "#####################################################################################\n",
    "def clean_pairs(pairs, input_lang, output_lang):\n",
    "    keep_pairs = np.zeros(pairs.shape[0])\n",
    "    for i in range(pairs.shape[0]):\n",
    "        input_sentence = pairs[i,0]\n",
    "        output_sentence = pairs[i,1]\n",
    "        keep_input = True\n",
    "        keep_output = True\n",
    "        for word in input_sentence.split(' '):\n",
    "            if word not in input_lang.word_dict:\n",
    "                keep_input = False\n",
    "                break\n",
    "        for word in output_sentence.split(' '):\n",
    "            if word not in output_lang.word_dict:\n",
    "                keep_output = False\n",
    "                break\n",
    "        if keep_input and keep_output:\n",
    "            keep_pairs[i] = 1\n",
    "    return np.squeeze(pairs[np.argwhere(keep_pairs == 1), :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display number of pairs processed, and split into train vs. validation vs. test\n",
    "* sentences too long / too short / have rare words are removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read and select sentences with: 3 < sentence length < 30\n",
      "Original number of total pairs = 159204\n",
      "Selected number of total pairs = 52711\n",
      "------------------------------------\n",
      "German: original vocabulary size = 11405\n",
      "English: original vocabulary size = 7207\n",
      "------------------------------------\n",
      "Remove sentences with rare words (count < 10)\n",
      "German: trimmed vocabulary size = 1889\n",
      "English: trimmed vocabulary size = 1651\n",
      "------------------------------------\n",
      "Trimmed Number of total pairs = 30679\n",
      "Number of training pairs = 18407\n",
      "Number of validation pairs = 6136\n",
      "Number of test pairs = 6136\n"
     ]
    }
   ],
   "source": [
    "pairs, size_ori, size_new = read_string(file_name)\n",
    "print('Read and select sentences with: {} < sentence length < {}'.format(MIN_SENTENCE_LENGTH, MAX_SENTENCE_LENGTH))\n",
    "print('Original number of total pairs = {}'.format(size_ori))\n",
    "print('Selected number of total pairs = {}'.format(size_new))\n",
    "\n",
    "input_lang = tokenizer('German')\n",
    "input_lang.read_sentences(pairs[:, 0])\n",
    "output_lang = tokenizer('English')\n",
    "output_lang.read_sentences(pairs[:, 1])\n",
    "print('------------------------------------')\n",
    "print('{}: original vocabulary size = {}'.format(input_lang.name, input_lang.word_num))\n",
    "print('{}: original vocabulary size = {}'.format(output_lang.name, output_lang.word_num))\n",
    "\n",
    "input_lang.trim_word(MIN_WORD_COUNT)\n",
    "output_lang.trim_word(MIN_WORD_COUNT)\n",
    "print('------------------------------------')\n",
    "print('Remove sentences with rare words (count < {})'.format(MIN_WORD_COUNT))\n",
    "print('{}: trimmed vocabulary size = {}'.format(input_lang.name, input_lang.word_num))\n",
    "print('{}: trimmed vocabulary size = {}'.format(output_lang.name, output_lang.word_num))\n",
    "\n",
    "pairs = clean_pairs(pairs, input_lang, output_lang)\n",
    "np.random.seed(0)\n",
    "randord = np.random.permutation(range(pairs.shape[0])).tolist()\n",
    "pairs_train = pairs[randord[:int(pairs.shape[0]*0.6)],:]\n",
    "pairs_val = pairs[randord[int(pairs.shape[0]*0.6):int(pairs.shape[0]*0.8)],:]\n",
    "pairs_test = pairs[randord[int(pairs.shape[0]*0.8):],:]\n",
    "\n",
    "print('------------------------------------')\n",
    "print('Trimmed Number of total pairs = {}'.format(pairs.shape[0]))\n",
    "print('Number of training pairs = {}'.format(pairs_train.shape[0]))\n",
    "print('Number of validation pairs = {}'.format(pairs_val.shape[0]))\n",
    "print('Number of test pairs = {}'.format(pairs_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions to pad sentences for training mini batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#####################################################################################\n",
    "# convert sentence words into a list of indexes\n",
    "#####################################################################################\n",
    "def sentence_index(lang, sentence):\n",
    "    return [lang.word_dict[word] for word in sentence.split(' ')] + [token_END]\n",
    "\n",
    "#####################################################################################\n",
    "# pad sentence for mini batch training\n",
    "#####################################################################################\n",
    "def sentence_padding(sentence, max_length):\n",
    "    sentence += [token_PAD for i in range(max_length - len(sentence))]\n",
    "    return sentence\n",
    "\n",
    "#####################################################################################\n",
    "# generate random batch for training\n",
    "#####################################################################################\n",
    "def batch_generator(pairs, batch_size):\n",
    "    input_seqs = []\n",
    "    output_seqs = []\n",
    "    for i in range(batch_size):\n",
    "        pair = random.choice(pairs)\n",
    "        input_seqs.append(sentence_index(input_lang, pair[0]))\n",
    "        output_seqs.append(sentence_index(output_lang, pair[1]))\n",
    "    \n",
    "    seq_pairs = sorted(zip(input_seqs, output_seqs), key=lambda p: len(p[0]), reverse=True)\n",
    "    input_seqs, output_seqs = zip(*seq_pairs)\n",
    "    \n",
    "    input_lengths = [len(s) for s in input_seqs]\n",
    "    output_lengths = [len(s) for s in output_seqs]\n",
    "    input_seqs = [sentence_padding(s, max(input_lengths)) for s in input_seqs]\n",
    "    output_seqs = [sentence_padding(s, max(output_lengths)) for s in output_seqs]\n",
    "\n",
    "    input_batch = Variable(torch.LongTensor(input_seqs)).transpose(0, 1).cuda()\n",
    "    output_batch = Variable(torch.LongTensor(output_seqs)).transpose(0, 1).cuda()\n",
    "        \n",
    "    return input_batch, input_lengths, output_batch, output_lengths\n",
    "\n",
    "#####################################################################################\n",
    "# identify sentence before padding\n",
    "#####################################################################################\n",
    "def sentence_mask(sentence_length, max_len=None):\n",
    "    if max_len is None:\n",
    "        max_len = sentence_length.data.max()\n",
    "    batch_size = sentence_length.size(0)\n",
    "    seq_range = torch.range(0, max_len - 1).long()\n",
    "    seq_range_expand = seq_range.unsqueeze(0).expand(batch_size, max_len)\n",
    "    seq_range_expand = Variable(seq_range_expand)\n",
    "    if sentence_length.is_cuda:\n",
    "        seq_range_expand = seq_range_expand.cuda()\n",
    "    seq_length_expand = (sentence_length.unsqueeze(1)\n",
    "                         .expand_as(seq_range_expand))\n",
    "    return seq_range_expand < seq_length_expand\n",
    "\n",
    "#####################################################################################\n",
    "# compute cross_entropy loss on unpadded sentence\n",
    "#####################################################################################\n",
    "def sentence_cross_entropy(logits, target, length):\n",
    "    length = Variable(torch.LongTensor(length)).cuda()\n",
    "    logits_flat = logits.view(-1, logits.size(-1))\n",
    "    log_probs_flat = F.log_softmax(logits_flat, dim=1)\n",
    "    target_flat = target.view(-1, 1)\n",
    "    losses_flat = -torch.gather(log_probs_flat, dim=1, index=target_flat)\n",
    "    losses = losses_flat.view(*target.size())\n",
    "    mask = sentence_mask(sentence_length=length, max_len=target.size(1))\n",
    "    losses = losses * mask.float()\n",
    "    loss = losses.sum() / length.float().sum()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#####################################################################################\n",
    "# define encoder: \n",
    "# word embedding -> lstm\n",
    "#####################################################################################\n",
    "# encoder model\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_layers=1, dropout=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size, n_layers, dropout=self.dropout, bidirectional=True)\n",
    "        \n",
    "    def forward(self, input_batch, input_lengths):\n",
    "        embedded = self.embedding(input_batch)\n",
    "        packed = torch.nn.utils.rnn.pack_padded_sequence(embedded, input_lengths)\n",
    "        outputs, hidden = self.lstm(packed)\n",
    "        outputs, output_lengths = torch.nn.utils.rnn.pad_packed_sequence(outputs) \n",
    "        outputs = outputs[:, :, :self.hidden_size] + outputs[:, : ,self.hidden_size:] \n",
    "        return outputs, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define decoder with attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#####################################################################################\n",
    "# define decoder: \n",
    "# ((word embedding -> lstm) + encoder output)-> attention -> concat -> relu -> fc\n",
    "#####################################################################################\n",
    "# attention model\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, method_name, hidden_size):\n",
    "        super(Attention, self).__init__()        \n",
    "        self.method_name = method_name\n",
    "        self.hidden_size = hidden_size\n",
    "        self.attention = nn.Linear(self.hidden_size, hidden_size)\n",
    "        self.v = nn.Parameter(torch.FloatTensor(1, hidden_size))\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        max_length = encoder_outputs.size(0)\n",
    "        batch_size = encoder_outputs.size(1)\n",
    "\n",
    "        attention_energy = Variable(torch.zeros(batch_size, max_length)).cuda()\n",
    "        for nb in range(batch_size):\n",
    "            for nl in range(max_length):\n",
    "                attention_energy[nb, nl] = self.score(hidden[:, nb], encoder_outputs[nl, nb].unsqueeze(0))\n",
    "        return F.softmax(attention_energy).unsqueeze(1)\n",
    "    \n",
    "    def score(self, hidden, encoder_output):      \n",
    "        if self.method_name == 'general':            \n",
    "            energy = hidden.dot(self.attention(encoder_output))    \n",
    "        elif self.method_name == 'concat':\n",
    "            self.attention = nn.Linear(self.hidden_size * 2, hidden_size)\n",
    "            energy = self.v.dot(self.attention(torch.cat((hidden, encoder_output), 1)))\n",
    "        else:\n",
    "            energy = hidden.dot(encoder_output) \n",
    "        return energy\n",
    "\n",
    "# decoder model\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, attention_method, hidden_size, output_size, n_layers=1, dropout=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.attention_method = attention_method\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size, n_layers, dropout=dropout)\n",
    "        self.attention = Attention(attention_method, hidden_size)\n",
    "        self.fc1 = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, input_batch, last_hidden, encoder_outputs):\n",
    "\n",
    "        batch_size = input_batch.size(0)\n",
    "        embedded = self.embedding(input_batch).view(1, batch_size, self.hidden_size) \n",
    "        \n",
    "        rnn_output, hidden = self.lstm(embedded, last_hidden)\n",
    "\n",
    "        attention_weights = self.attention(rnn_output, encoder_outputs)\n",
    "        context = attention_weights.bmm(encoder_outputs.transpose(0, 1)) \n",
    "\n",
    "        rnn_output = rnn_output.squeeze(0) \n",
    "        context = context.squeeze(1)       \n",
    "        concat_input = torch.cat((rnn_output, context), 1)\n",
    "        concat_output = self.relu(self.fc1(concat_input))\n",
    "\n",
    "        output = self.fc2(concat_output)\n",
    "        return output, hidden, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#####################################################################################\n",
    "# define training: use teacher forcing for training\n",
    "#####################################################################################\n",
    "def train(input_batch, input_lengths, output_batch, output_lengths, \n",
    "          encoder, decoder, encoder_optimizer, decoder_optimizer, criterion):\n",
    "    \n",
    "    loss = 0 \n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    \n",
    "    encoder_outputs, encoder_hidden = encoder(input_batch, input_lengths)\n",
    "    decoder_input = Variable(torch.LongTensor([token_BEGIN] * batch_size)).cuda()\n",
    "    decoder_hidden = (encoder_hidden[0][:decoder.n_layers], encoder_hidden[1][:decoder.n_layers])\n",
    "\n",
    "    max_output_length = max(output_lengths)\n",
    "    all_decoder_outputs = Variable(torch.zeros(max_output_length, batch_size, decoder.output_size)).cuda()\n",
    "\n",
    "    for t in range(max_output_length):\n",
    "        decoder_output, decoder_hidden, decoder_Attention = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "        all_decoder_outputs[t] = decoder_output\n",
    "        decoder_input = output_batch[t] \n",
    "\n",
    "    loss = sentence_cross_entropy(\n",
    "        all_decoder_outputs.transpose(0, 1).contiguous(), \n",
    "        output_batch.transpose(0, 1).contiguous(), \n",
    "        output_lengths\n",
    "    )\n",
    "    loss.backward()    \n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    \n",
    "    return loss.data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define evaluatioin function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#####################################################################################\n",
    "# define evaluation function: record loss and bleu score\n",
    "#####################################################################################\n",
    "def evaluate(input_lang, output_lang, pairs, encoder, decoder, max_length = MAX_SENTENCE_LENGTH):\n",
    "    \n",
    "    output_sentences = []\n",
    "    bleu_scores = []\n",
    "    losses = []\n",
    "    for pair in pairs:\n",
    "\n",
    "        input_batch = [sentence_index(input_lang, pair[0])]\n",
    "        input_lengths = [len(s) for s in input_batch]\n",
    "        input_batch = Variable(torch.LongTensor(input_batch), volatile=True).transpose(0, 1).cuda()\n",
    "\n",
    "        output_batch = [sentence_index(output_lang, pair[1])]\n",
    "        output_lengths = [len(s) for s in output_batch]    \n",
    "        output_batch = [sentence_padding(s, max_length) for s in output_batch]\n",
    "        output_batch = Variable(torch.LongTensor(output_batch), volatile=True).transpose(0, 1).cuda()\n",
    "\n",
    "        encoder.train(False)\n",
    "        decoder.train(False)\n",
    "\n",
    "        encoder_outputs, encoder_hidden = encoder(input_batch, input_lengths)\n",
    "        decoder_input = Variable(torch.LongTensor([token_BEGIN]), volatile=True).cuda()\n",
    "        decoder_hidden = (encoder_hidden[0][:decoder.n_layers], encoder_hidden[1][:decoder.n_layers])\n",
    "\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length + 1, max_length + 1)\n",
    "        all_decoder_outputs = Variable(torch.zeros(max_length, 1, decoder.output_size)).cuda()\n",
    "\n",
    "        for n_curr in range(max_length):\n",
    "            decoder_output, decoder_hidden, _ = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "            all_decoder_outputs[n_curr] = decoder_output\n",
    "\n",
    "            _, top_index = decoder_output.data.topk(1)\n",
    "            index_curr = top_index[0][0]\n",
    "            if index_curr == token_END:\n",
    "                decoded_words.append('TEND')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang.index_dict[index_curr])\n",
    "\n",
    "            decoder_input = Variable(torch.LongTensor([index_curr])).cuda()\n",
    "\n",
    "        loss = sentence_cross_entropy(all_decoder_outputs.transpose(0, 1).contiguous(),\n",
    "                                    output_batch.transpose(0, 1).contiguous(), output_lengths)\n",
    "\n",
    "        encoder.train(True)\n",
    "        decoder.train(True)\n",
    "        \n",
    "        output_sentence = ' '.join(decoded_words[:-1])\n",
    "        output_sentences.append(output_sentence)\n",
    "        reference = [pair[1].split(' ')]\n",
    "        hypothesis = output_sentence.split(' ')\n",
    "        bleu_scores.append(nltk.translate.bleu_score.sentence_bleu(reference,hypothesis))    \n",
    "        losses.append(loss.data[0])\n",
    "    \n",
    "    return output_sentences, losses, bleu_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define hyperparameters and initialize model\n",
    "* print summary of encoder and decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder(\n",
      "  (embedding): Embedding(1889, 256)\n",
      "  (lstm): LSTM(256, 256, num_layers=2, dropout=0.1, bidirectional=True)\n",
      ")\n",
      "Decoder(\n",
      "  (embedding): Embedding(1651, 256)\n",
      "  (lstm): LSTM(256, 256, num_layers=2, dropout=0.1)\n",
      "  (attention): Attention(\n",
      "    (attention): Linear(in_features=256, out_features=256, bias=True)\n",
      "  )\n",
      "  (fc1): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (relu): ReLU(inplace)\n",
      "  (fc2): Linear(in_features=256, out_features=1651, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "attention_method = 'general'\n",
    "hidden_size = 256\n",
    "n_layers = 2\n",
    "dropout = 0.1\n",
    "batch_size = 300\n",
    "\n",
    "encoder_learning_rate = 0.001\n",
    "decoder_learning_rate = 0.005\n",
    "n_epochs = 100\n",
    "iter_epoch = 10 \n",
    "iter_max   = n_epochs * iter_epoch\n",
    "\n",
    "# initialize models\n",
    "encoder = Encoder(input_lang.word_num, hidden_size, n_layers, dropout=dropout).cuda()\n",
    "decoder = Decoder(attention_method, hidden_size, output_lang.word_num, n_layers, dropout=dropout).cuda()\n",
    "\n",
    "# initialize optimizers and criterion\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=encoder_learning_rate)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=decoder_learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "print(encoder)\n",
    "print(decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Begin training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 train loss = 7.36 bleu = 0.048 | val loss = 7.37 bleu = 0.045\n",
      "Epoch 1 train loss = 6.36 bleu = 0.023 | val loss = 6.38 bleu = 0.022\n",
      "Epoch 2 train loss = 5.71 bleu = 0.247 | val loss = 5.75 bleu = 0.242\n",
      "Epoch 3 train loss = 5.34 bleu = 0.344 | val loss = 5.40 bleu = 0.340\n",
      "Epoch 4 train loss = 5.09 bleu = 0.410 | val loss = 5.15 bleu = 0.404\n",
      "Epoch 5 train loss = 4.69 bleu = 0.497 | val loss = 4.77 bleu = 0.485\n",
      "Epoch 6 train loss = 4.37 bleu = 0.542 | val loss = 4.44 bleu = 0.536\n",
      "Epoch 7 train loss = 4.12 bleu = 0.569 | val loss = 4.23 bleu = 0.563\n",
      "Epoch 8 train loss = 4.07 bleu = 0.576 | val loss = 4.19 bleu = 0.571\n",
      "Epoch 9 train loss = 3.90 bleu = 0.583 | val loss = 4.07 bleu = 0.578\n",
      "Epoch 10 train loss = 3.68 bleu = 0.600 | val loss = 3.87 bleu = 0.591\n",
      "Epoch 11 train loss = 3.60 bleu = 0.605 | val loss = 3.82 bleu = 0.597\n",
      "Epoch 12 train loss = 3.42 bleu = 0.620 | val loss = 3.69 bleu = 0.610\n",
      "Epoch 13 train loss = 3.27 bleu = 0.630 | val loss = 3.57 bleu = 0.618\n",
      "Epoch 14 train loss = 3.18 bleu = 0.641 | val loss = 3.55 bleu = 0.624\n",
      "Epoch 15 train loss = 2.93 bleu = 0.660 | val loss = 3.35 bleu = 0.638\n",
      "Epoch 16 train loss = 2.92 bleu = 0.666 | val loss = 3.41 bleu = 0.638\n",
      "Epoch 17 train loss = 2.71 bleu = 0.679 | val loss = 3.22 bleu = 0.655\n",
      "Epoch 18 train loss = 2.66 bleu = 0.688 | val loss = 3.25 bleu = 0.652\n",
      "Epoch 19 train loss = 2.48 bleu = 0.700 | val loss = 3.08 bleu = 0.663\n",
      "Epoch 20 train loss = 2.42 bleu = 0.708 | val loss = 3.08 bleu = 0.665\n",
      "Epoch 21 train loss = 2.36 bleu = 0.719 | val loss = 3.14 bleu = 0.673 best model!\n",
      "Epoch 22 train loss = 2.30 bleu = 0.730 | val loss = 3.07 bleu = 0.683 best model!\n",
      "Epoch 23 train loss = 2.26 bleu = 0.732 | val loss = 3.06 bleu = 0.678 best model!\n",
      "Epoch 24 train loss = 2.08 bleu = 0.745 | val loss = 2.94 bleu = 0.689 best model!\n",
      "Epoch 25 train loss = 2.05 bleu = 0.755 | val loss = 3.01 bleu = 0.689\n",
      "Epoch 26 train loss = 2.02 bleu = 0.762 | val loss = 3.01 bleu = 0.695\n",
      "Epoch 27 train loss = 1.92 bleu = 0.768 | val loss = 2.98 bleu = 0.700\n",
      "Epoch 28 train loss = 1.93 bleu = 0.772 | val loss = 3.01 bleu = 0.697\n",
      "Epoch 29 train loss = 1.85 bleu = 0.778 | val loss = 3.00 bleu = 0.700\n",
      "Epoch 30 train loss = 1.76 bleu = 0.789 | val loss = 2.97 bleu = 0.705\n",
      "Epoch 31 train loss = 1.72 bleu = 0.793 | val loss = 2.97 bleu = 0.705\n",
      "Epoch 32 train loss = 1.72 bleu = 0.798 | val loss = 3.00 bleu = 0.708\n",
      "Epoch 33 train loss = 1.66 bleu = 0.806 | val loss = 3.01 bleu = 0.710\n",
      "Epoch 34 train loss = 1.62 bleu = 0.809 | val loss = 3.05 bleu = 0.707\n",
      "Epoch 35 train loss = 1.58 bleu = 0.816 | val loss = 3.08 bleu = 0.709\n",
      "Epoch 36 train loss = 1.56 bleu = 0.817 | val loss = 3.08 bleu = 0.711\n",
      "Epoch 37 train loss = 1.51 bleu = 0.824 | val loss = 3.03 bleu = 0.713\n",
      "Epoch 38 train loss = 1.47 bleu = 0.828 | val loss = 3.05 bleu = 0.717\n",
      "Epoch 39 train loss = 1.45 bleu = 0.829 | val loss = 3.08 bleu = 0.719\n",
      "Epoch 40 train loss = 1.36 bleu = 0.837 | val loss = 3.08 bleu = 0.717\n",
      "Epoch 41 train loss = 1.36 bleu = 0.837 | val loss = 3.09 bleu = 0.718\n",
      "Epoch 42 train loss = 1.32 bleu = 0.845 | val loss = 3.11 bleu = 0.717\n",
      "Epoch 43 train loss = 1.33 bleu = 0.845 | val loss = 3.10 bleu = 0.716\n",
      "Epoch 44 train loss = 1.28 bleu = 0.850 | val loss = 3.14 bleu = 0.722\n",
      "Epoch 45 train loss = 1.24 bleu = 0.852 | val loss = 3.10 bleu = 0.720\n",
      "Epoch 46 train loss = 1.17 bleu = 0.861 | val loss = 3.14 bleu = 0.724\n",
      "Epoch 47 train loss = 1.16 bleu = 0.866 | val loss = 3.12 bleu = 0.721\n",
      "Epoch 48 train loss = 1.15 bleu = 0.866 | val loss = 3.18 bleu = 0.722\n",
      "Epoch 49 train loss = 1.08 bleu = 0.875 | val loss = 3.18 bleu = 0.725\n",
      "Epoch 50 train loss = 1.10 bleu = 0.873 | val loss = 3.28 bleu = 0.726\n",
      "Epoch 51 train loss = 1.08 bleu = 0.874 | val loss = 3.28 bleu = 0.719\n",
      "Epoch 52 train loss = 1.05 bleu = 0.877 | val loss = 3.17 bleu = 0.724\n",
      "Epoch 53 train loss = 1.04 bleu = 0.880 | val loss = 3.26 bleu = 0.720\n",
      "Epoch 54 train loss = 1.00 bleu = 0.881 | val loss = 3.20 bleu = 0.724\n",
      "Epoch 55 train loss = 0.98 bleu = 0.887 | val loss = 3.25 bleu = 0.725\n",
      "Epoch 56 train loss = 0.94 bleu = 0.891 | val loss = 3.30 bleu = 0.723\n",
      "Epoch 57 train loss = 0.97 bleu = 0.891 | val loss = 3.29 bleu = 0.724\n",
      "Epoch 58 train loss = 0.93 bleu = 0.894 | val loss = 3.33 bleu = 0.724\n",
      "Epoch 59 train loss = 0.90 bleu = 0.897 | val loss = 3.29 bleu = 0.723\n",
      "Epoch 60 train loss = 0.92 bleu = 0.901 | val loss = 3.37 bleu = 0.728\n",
      "Epoch 61 train loss = 0.87 bleu = 0.904 | val loss = 3.43 bleu = 0.726\n",
      "Epoch 62 train loss = 0.84 bleu = 0.904 | val loss = 3.44 bleu = 0.722\n",
      "Epoch 63 train loss = 0.82 bleu = 0.909 | val loss = 3.39 bleu = 0.724\n",
      "Epoch 64 train loss = 0.79 bleu = 0.913 | val loss = 3.39 bleu = 0.727\n",
      "Epoch 65 train loss = 0.86 bleu = 0.907 | val loss = 3.46 bleu = 0.723\n",
      "Epoch 66 train loss = 0.81 bleu = 0.910 | val loss = 3.45 bleu = 0.730\n",
      "Epoch 67 train loss = 0.81 bleu = 0.911 | val loss = 3.45 bleu = 0.726\n",
      "Epoch 68 train loss = 0.83 bleu = 0.911 | val loss = 3.50 bleu = 0.725\n",
      "Epoch 69 train loss = 0.81 bleu = 0.913 | val loss = 3.51 bleu = 0.724\n",
      "Epoch 70 train loss = 0.82 bleu = 0.913 | val loss = 3.54 bleu = 0.727\n",
      "Epoch 71 train loss = 0.79 bleu = 0.913 | val loss = 3.51 bleu = 0.724\n",
      "Epoch 72 train loss = 0.77 bleu = 0.916 | val loss = 3.52 bleu = 0.727\n",
      "Epoch 73 train loss = 0.75 bleu = 0.920 | val loss = 3.55 bleu = 0.727\n",
      "Epoch 74 train loss = 0.75 bleu = 0.919 | val loss = 3.59 bleu = 0.726\n",
      "Epoch 75 train loss = 0.73 bleu = 0.924 | val loss = 3.53 bleu = 0.729\n",
      "Epoch 76 train loss = 0.74 bleu = 0.921 | val loss = 3.65 bleu = 0.729\n",
      "Epoch 77 train loss = 0.71 bleu = 0.923 | val loss = 3.55 bleu = 0.732\n",
      "Epoch 78 train loss = 0.65 bleu = 0.928 | val loss = 3.58 bleu = 0.732\n",
      "Epoch 79 train loss = 0.69 bleu = 0.929 | val loss = 3.58 bleu = 0.729\n",
      "Epoch 80 train loss = 0.67 bleu = 0.929 | val loss = 3.66 bleu = 0.730\n",
      "Epoch 81 train loss = 0.67 bleu = 0.930 | val loss = 3.60 bleu = 0.730\n",
      "Epoch 82 train loss = 0.69 bleu = 0.927 | val loss = 3.64 bleu = 0.725\n",
      "Epoch 83 train loss = 0.68 bleu = 0.928 | val loss = 3.54 bleu = 0.731\n",
      "Epoch 84 train loss = 0.67 bleu = 0.928 | val loss = 3.61 bleu = 0.728\n",
      "Epoch 85 train loss = 0.66 bleu = 0.930 | val loss = 3.65 bleu = 0.728\n",
      "Epoch 86 train loss = 0.65 bleu = 0.931 | val loss = 3.64 bleu = 0.729\n",
      "Epoch 87 train loss = 0.68 bleu = 0.929 | val loss = 3.74 bleu = 0.727\n",
      "Epoch 88 train loss = 0.67 bleu = 0.930 | val loss = 3.72 bleu = 0.728\n",
      "Epoch 89 train loss = 0.65 bleu = 0.933 | val loss = 3.71 bleu = 0.731\n",
      "Epoch 90 train loss = 0.62 bleu = 0.936 | val loss = 3.70 bleu = 0.730\n",
      "Epoch 91 train loss = 0.61 bleu = 0.939 | val loss = 3.69 bleu = 0.728\n",
      "Epoch 92 train loss = 0.59 bleu = 0.940 | val loss = 3.71 bleu = 0.730\n",
      "Epoch 93 train loss = 0.59 bleu = 0.939 | val loss = 3.72 bleu = 0.729\n",
      "Epoch 94 train loss = 0.59 bleu = 0.939 | val loss = 3.72 bleu = 0.730\n",
      "Epoch 95 train loss = 0.57 bleu = 0.941 | val loss = 3.70 bleu = 0.731\n",
      "Epoch 96 train loss = 0.59 bleu = 0.938 | val loss = 3.72 bleu = 0.728\n",
      "Epoch 97 train loss = 0.56 bleu = 0.941 | val loss = 3.71 bleu = 0.731\n",
      "Epoch 98 train loss = 0.59 bleu = 0.940 | val loss = 3.73 bleu = 0.732\n",
      "Epoch 99 train loss = 0.56 bleu = 0.942 | val loss = 3.78 bleu = 0.732\n"
     ]
    }
   ],
   "source": [
    "#####################################################################################\n",
    "# training process:\n",
    "# save best models of encoder and decoder, based on validation loss\n",
    "#####################################################################################\n",
    "LOSS_train = []\n",
    "BLEU_train = []\n",
    "LOSS_val = []\n",
    "BLEU_val = []\n",
    "\n",
    "niter = 0\n",
    "history_loss_best = 10**6\n",
    "history_tolerance = 0\n",
    "best_epoch = 0\n",
    "\n",
    "while niter < iter_max:    \n",
    "    input_batch, input_lengths, output_batch, output_lengths = batch_generator(pairs_train, batch_size)\n",
    "    loss_curr = train(input_batch, input_lengths, output_batch, output_lengths,\n",
    "                       encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "    \n",
    "    if niter % iter_epoch == 0:\n",
    "        _, loss_train, bleu_train = evaluate(\n",
    "            input_lang, output_lang, pairs_train, encoder, decoder, MAX_SENTENCE_LENGTH) \n",
    "        _, loss_val, bleu_val = evaluate(\n",
    "            input_lang, output_lang, pairs_val, encoder, decoder, MAX_SENTENCE_LENGTH)      \n",
    "        \n",
    "        LOSS_train.append(sum(loss_train)/len(loss_train))\n",
    "        BLEU_train.append(sum(bleu_train)/len(bleu_train))\n",
    "        LOSS_val.append(sum(loss_val)/len(loss_val))\n",
    "        BLEU_val.append(sum(bleu_val)/len(bleu_val))\n",
    "        \n",
    "        nepoch = niter/iter_epoch\n",
    "        \n",
    "        if nepoch > 20 and LOSS_val[nepoch] < history_loss_best and history_tolerance <= 10:\n",
    "            torch.save(encoder.state_dict(), './model_encoder.pt')\n",
    "            torch.save(decoder.state_dict(), './model_decoder.pt')\n",
    "            history_loss_best = LOSS_val[nepoch] \n",
    "            history_tolerance = 0\n",
    "            best_epoch = nepoch\n",
    "            print('Epoch {} train loss = {:.2f} bleu = {:.3f} | val loss = {:.2f} bleu = {:.3f} best model!'.format(\n",
    "            nepoch, LOSS_train[-1], BLEU_train[-1], LOSS_val[-1], BLEU_val[-1]))\n",
    "        else:\n",
    "            if nepoch > 20: history_tolerance += 1\n",
    "            print('Epoch {} train loss = {:.2f} bleu = {:.3f} | val loss = {:.2f} bleu = {:.3f}'.format(\n",
    "                nepoch, LOSS_train[-1], BLEU_train[-1], LOSS_val[-1], BLEU_val[-1]))\n",
    "                    \n",
    "    niter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot training vs. validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f3c219b3c10>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3c27054c10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(121)\n",
    "plt.plot(range(n_epochs), LOSS_train, 'ro-', label='Training')\n",
    "plt.plot(range(n_epochs), LOSS_val, 'gd-', label='Validation')\n",
    "plt.title('Loss vs. Epoch')\n",
    "plt.xlabel('Number of Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.subplot(122)\n",
    "plt.plot(range(n_epochs), BLEU_train, 'ro-', label='Training')\n",
    "plt.plot(range(n_epochs), BLEU_val, 'gd-', label='Validation')\n",
    "plt.title('BLEU vs. Epoch')\n",
    "plt.xlabel('Number of Epoch')\n",
    "plt.ylabel('BLEU')\n",
    "plt.grid()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Begin evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss = 2.99136037543\n",
      "Test BLEU = 0.685\n",
      "Example #1\n",
      "Input German = weit du wo er wohnt\n",
      "Reference English = do you know where he lives\n",
      "Translated English = do you know where he lives\n",
      "Example #2\n",
      "Input German = wisst ihr wo er wohnt\n",
      "Reference English = do you know where he lives\n",
      "Translated English = do you know where he lives\n",
      "Example #3\n",
      "Input German = wo hast du tom gefunden\n",
      "Reference English = where did you find tom\n",
      "Translated English = where did you find tom\n",
      "Example #4\n",
      "Input German = bist du wach\n",
      "Reference English = are you awake\n",
      "Translated English = are you awake\n",
      "Example #5\n",
      "Input German = ich brauche ein neues auto\n",
      "Reference English = i need a new car\n",
      "Translated English = i need a new car\n"
     ]
    }
   ],
   "source": [
    "#####################################################################################\n",
    "# test process:\n",
    "# evaluate on test set using the best models saved\n",
    "#####################################################################################\n",
    "encoder.load_state_dict(torch.load('./model_encoder.pt'))\n",
    "decoder.load_state_dict(torch.load('./model_decoder.pt'))\n",
    "output_sentences, loss_test, bleu_test = evaluate(\n",
    "    input_lang, output_lang, pairs_test, encoder, decoder, MAX_SENTENCE_LENGTH) \n",
    "\n",
    "print(\"Test loss = {}\".format(sum(loss_test)/len(loss_test)))\n",
    "print(\"Test BLEU = {:.3f}\".format(sum(bleu_test)/len(bleu_test)))\n",
    "\n",
    "loss_sort = np.argsort(loss_test)\n",
    "for example in range(5):\n",
    "    sentence_german = pairs_test[loss_sort[example],0]\n",
    "    sentence_english = pairs_test[loss_sort[example],1]\n",
    "    sentence_translated = output_sentences[loss_sort[example]]\n",
    "    print('Example #{}'.format(example+1))\n",
    "    print('Input German = {}'.format(sentence_german))\n",
    "    print('Reference English = {}'.format(sentence_english))\n",
    "    print('Translated English = {}'.format(sentence_translated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
